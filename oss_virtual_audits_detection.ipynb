{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b221b0-1382-4128-b0c2-33ce5ce01441",
   "metadata": {},
   "source": [
    "# Object detection and segmentation with the Gemini API\n",
    "\n",
    "\n",
    "**References:**\n",
    "* [Conversational image segmentation with Gemini 2.5](https://developers.googleblog.com/en/conversational-image-segmentation-gemini-2-5/)\n",
    "* [Use Gemini 2.5 for Zero-Shot Object Detection & Segmentation](https://blog.roboflow.com/gemini-2-5-object-detection-segmentation/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a6f0f-3165-4984-97b7-8a8d628cfac2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e932a5-6fe9-4f2f-9b83-989f0461de67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install\n",
    "#!pip install google-genai supervision python-dotenv\n",
    "\n",
    "# Standard library\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party libraries\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import errors as genai_errors\n",
    "from google.genai import types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f2b22-15a3-4e64-9722-f8ef6e81bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from environment file\n",
    "load_dotenv()\n",
    "load_dotenv(\"gemini_api_key.env\")\n",
    "client = genai.Client(api_key = os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e9a86-0ea0-46ba-b856-ad1a977b5356",
   "metadata": {},
   "source": [
    "## Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b038f-b195-4de4-9794-785c1c9c7b0a",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Spatial understanding works best with the **Gemini 2.0 Flash** model.  \n",
    "It performs even better with **Gemini 2.5 models** (like `gemini-2.5-pro`), which are more capable \"thinking models\" — though slightly slower.  \n",
    "Some advanced features, such as **image segmentation**, are only supported by **Gemini 2.5 models**.\n",
    "\n",
    "**Available model options:**\n",
    "- `gemini-2.0-flash`\n",
    "- `gemini-2.5-flash-lite`\n",
    "- `gemini-2.5-flash-lite-preview-09-2025`\n",
    "- `gemini-2.5-flash`\n",
    "- `gemini-2.5-flash-preview-09-2025`\n",
    "- `gemini-2.5-pro`\n",
    "\n",
    "**Temperature (creativity control):**\n",
    "- Controls randomness/creativity of model output.  \n",
    "- `0.0` → very deterministic, consistent output (best for precise tasks).  \n",
    "- `0.5` → moderately creative (good balance for tasks like bounding boxes).  \n",
    "- `1.0` → more creative, potentially less consistent output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abc997-d2a1-4b0c-bb6a-67fe0c9c080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root_path = Path(r\"C:\\Users\\amand\\Amanda\\GitHub\\virtual_audit_ai\\street_view_images\")\n",
    "excel_file = Path(r\"C:\\Users\\amand\\Amanda\\GitHub\\virtual_audit_ai\\coordinates_annotated.xlsx\")\n",
    "output_folder = Path(r\"C:\\Users\\amand\\Amanda\\GitHub\\virtual_audit_ai\\street_view_outputs\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model settings\n",
    "model_gemini_2_0 = \"gemini-2.0-flash\"\n",
    "temperature = 0.2\n",
    "safety_settings = []\n",
    "max_retries = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db908ebc-cab5-4f5d-be33-602bc2ba3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "city_name = \"Belo Horizonte\"\n",
    "id_name = \"562002001\"\n",
    "point_name = \"point_1\"\n",
    "\n",
    "selected_city = root_path / city_name\n",
    "selected_id = selected_city / id_name\n",
    "selected_point = selected_id / point_name\n",
    "\n",
    "# Verifications\n",
    "if not selected_city.exists():\n",
    "    raise ValueError(f\" City '{city_name}' not found.\")\n",
    "\n",
    "if not selected_id.exists():\n",
    "    raise ValueError(f\" ID '{id_name}' not found inside {city_name}.\")\n",
    "\n",
    "if not selected_point.exists():\n",
    "    raise ValueError(f\" Point folder '{point_name}' not found inside {id_name}.\")\n",
    "\n",
    "# Load images only for this specific point folder\n",
    "test_images = list(selected_point.glob(\"*.[jp][pn]g\"))\n",
    "\n",
    "print(f\" City: {selected_city.name}\")\n",
    "print(f\" ID: {selected_id.name}\")\n",
    "print(f\" Point: {selected_point.name}\")\n",
    "print(f\" Total images found to process: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda1e0e-46c2-46f7-b8a6-bc1956e5ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Prompts Dictionary\n",
    "prompts_dict = {\n",
    "    \"buildings\": (\n",
    "        \"Detect ONLY buildings in this Street View image. \"\n",
    "        \"Include houses, apartment buildings, commercial buildings, or other permanent built structures. \"\n",
    "        \"Do NOT label trees, poles, vehicles, walls, fences, or temporary constructions. \"\n",
    "        \"Output strictly a JSON list of bounding boxes with 'box_2d' and 'label':'building'.\"\n",
    "    ),\n",
    "    \"trees\": (\n",
    "        \"Detect ONLY real trees in this Street View image. \"\n",
    "        \"Only label plants with a visible leafy canopy. \"\n",
    "        \"Do NOT label shrubs, grass, poles, trunks, artificial trees, or fences. \"\n",
    "        \"Output strictly a JSON list of bounding boxes with 'box_2d' and 'label':'tree'.\"\n",
    "    ),\n",
    "    \"waste_containers\": (\n",
    "    \"Detect ONLY public waste containers in this Street View image. \"\n",
    "    \"Include fixed dumpsters, metal or plastic public trash bins, and street-side waste baskets. \"\n",
    "    \"Do NOT label loose trash on the ground, cardboard boxes, improvised containers, recycling trucks, or small household bins. \"\n",
    "    \"Focus on containers that are clearly designed for public trash collection, such as the standard Brazilian street waste bins (cylindrical, rectangular, or square). \"\n",
    "    \"Output strictly a JSON list of bounding boxes with 'box_2d' coordinates and 'label':'waste_container'.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Ensure Excel columns exist\n",
    "for item_key in prompts_dict.keys():\n",
    "    if item_key not in df.columns:\n",
    "        df[item_key] = \".\"\n",
    "\n",
    "print(f\" Ready to process: {list(prompts_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84fd59-da76-4453-ae26-1888c269cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start processing images\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, image_path in enumerate(test_images, start=1):\n",
    "    try:\n",
    "        # Extract metadata\n",
    "        parts = image_path.stem.split(\"_\")\n",
    "        current_id = parts[0]\n",
    "        current_point_num = parts[1].lstrip(\"p\") \n",
    "\n",
    "        # Load and resize image\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        target_height = int(1024 * height / width)\n",
    "        resized_image = image.resize((1024, target_height), Image.Resampling.LANCZOS)\n",
    "        resolution_wh = resized_image.size\n",
    "\n",
    "        # Initialize image for annotation\n",
    "        annotated = resized_image.copy()\n",
    "        \n",
    "        # Visual configuration\n",
    "        thickness = sv.calculate_optimal_line_thickness(resolution_wh)\n",
    "        text_scale = sv.calculate_optimal_text_scale(resolution_wh)\n",
    "        box_annotator = sv.BoxAnnotator(thickness=thickness)\n",
    "        label_annotator = sv.LabelAnnotator(\n",
    "            smart_position=True, text_color=sv.Color.BLACK,\n",
    "            text_scale=text_scale, text_position=sv.Position.CENTER\n",
    "        )\n",
    "        \n",
    "        save_image = False \n",
    "\n",
    "        # Loop through prompts\n",
    "        for prompt_index, (target_item, active_prompt) in enumerate(prompts_dict.items()):\n",
    "            excel_col_name = target_item\n",
    "\n",
    "            # API call with retry\n",
    "            current_retry = 0\n",
    "            wait_time = 1\n",
    "            detections_json = None\n",
    "\n",
    "            while current_retry < max_retries:\n",
    "                try:\n",
    "                    response = client.models.generate_content(\n",
    "                        model=model_gemini_2_0,\n",
    "                        contents=[resized_image, active_prompt],\n",
    "                        config=types.GenerateContentConfig(\n",
    "                            temperature=temperature,\n",
    "                            safety_settings=safety_settings,\n",
    "                            response_mime_type=\"application/json\"))\n",
    "\n",
    "                    text = response.text\n",
    "                    text_clean = text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                    json_start = text_clean.find(\"[\")\n",
    "                    json_end = text_clean.rfind(\"]\") + 1\n",
    "\n",
    "                    if json_start != -1 and json_end != -1:\n",
    "                        detections_json = json.loads(text_clean[json_start:json_end])\n",
    "                        break\n",
    "                    else:\n",
    "                        detections_json = []\n",
    "                        break \n",
    "\n",
    "                except Exception:\n",
    "                    current_retry += 1\n",
    "                    time.sleep(wait_time)\n",
    "                    wait_time *= 2\n",
    "            \n",
    "            if detections_json is None:\n",
    "                detections_json = []\n",
    "\n",
    "            # Update excel and prepare annotation\n",
    "            mask = (df[\"id\"].astype(str) == str(current_id)) & (df[\"points\"].astype(str) == str(current_point_num))\n",
    "            \n",
    "            if mask.any():\n",
    "                if len(detections_json) > 0:\n",
    "                    df.loc[mask, excel_col_name] = \"Yes\"\n",
    "                    save_image = True\n",
    "\n",
    "                    # Create bounding boxes\n",
    "                    xyxy = []\n",
    "                    labels = []\n",
    "                    class_ids = []\n",
    "\n",
    "                    for item in detections_json:\n",
    "                        if \"box_2d\" in item:\n",
    "                            ymin, xmin, ymax, xmax = item[\"box_2d\"]\n",
    "                            x1 = (xmin / 1000) * resolution_wh[0]\n",
    "                            y1 = (ymin / 1000) * resolution_wh[1]\n",
    "                            x2 = (xmax / 1000) * resolution_wh[0]\n",
    "                            y2 = (ymax / 1000) * resolution_wh[1]\n",
    "\n",
    "                            xyxy.append([x1, y1, x2, y2])\n",
    "                            labels.append(item.get(\"label\", target_item))\n",
    "                            class_ids.append(prompt_index)\n",
    "\n",
    "                    if len(xyxy) > 0:\n",
    "                        detections = sv.Detections(\n",
    "                            xyxy=np.array(xyxy),\n",
    "                            class_id=np.array(class_ids)\n",
    "                        )\n",
    "                        annotated = box_annotator.annotate(scene=annotated, detections=detections)\n",
    "                        annotated = label_annotator.annotate(scene=annotated, detections=detections, labels=labels)\n",
    "\n",
    "                else:\n",
    "                    df.loc[mask, excel_col_name] = \"No\"\n",
    "\n",
    "        # Save annotated image if any detection\n",
    "        if save_image:\n",
    "            final_output_path = output_folder / city_name / id_name / point_name\n",
    "            final_output_path.mkdir(parents=True, exist_ok=True)\n",
    "            file_save_path = final_output_path / f\"{image_path.stem}_annotated.jpg\"\n",
    "            annotated.save(file_save_path)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"[{idx}/{len(test_images)}] {image_path.name} processed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{idx}/{len(test_images)}] {image_path.name} Error: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save Excel\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "# Execution time\n",
    "end_time = time.time()\n",
    "total_seconds = end_time - start_time\n",
    "minutes = int(total_seconds // 60)\n",
    "seconds = total_seconds % 60\n",
    "print(f\"\\nProcessing complete in {minutes} minutes and {seconds:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb5f74-8e84-4627-86d4-f9118a3f4769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
